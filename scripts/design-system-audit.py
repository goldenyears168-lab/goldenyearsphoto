#!/usr/bin/env python3
"""
è¨­è¨ˆç³»çµ±ä¸€è‡´æ€§ç¨½æ ¸è…³æœ¬
æƒæå°ˆæ¡ˆç¨‹å¼ç¢¼ï¼Œé©—è­‰é¡è‰²ã€å­—é«”ã€é–“è·ã€åœ“è§’ã€é™°å½±ã€UI å…ƒä»¶ç­‰æ˜¯å¦ä¸€è‡´
"""

import re
import json
import os
from pathlib import Path
from collections import defaultdict, Counter
from typing import Dict, List, Set, Tuple, Any
from datetime import datetime
import colorsys

# å°ˆæ¡ˆæ ¹ç›®éŒ„
PROJECT_ROOT = Path(__file__).parent.parent
SRC_DIR = PROJECT_ROOT / "src"

# æƒæçš„æª”æ¡ˆé¡å‹
SCAN_EXTENSIONS = {'.njk', '.css', '.js', '.html'}

# è¨­è¨ˆ Token ä¾†æºï¼ˆå¾ tailwind.config.js å’Œ main.css æå–ï¼‰
DESIGN_TOKENS = {
    'colors': {},
    'spacing': {},
    'fontSize': {},
    'fontWeight': {},
    'borderRadius': {},
    'boxShadow': {},
    'lineHeight': {},
}

def hex_to_rgb(hex_color: str) -> Tuple[int, int, int]:
    """å°‡ HEX é¡è‰²è½‰æ›ç‚º RGB"""
    hex_color = hex_color.lstrip('#')
    if len(hex_color) == 3:
        hex_color = ''.join([c*2 for c in hex_color])
    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))

def rgb_to_hsl(r: int, g: int, b: int) -> Tuple[float, float, float]:
    """å°‡ RGB è½‰æ›ç‚º HSL"""
    r, g, b = r/255.0, g/255.0, b/255.0
    h, l, s = colorsys.rgb_to_hls(r, g, b)
    return (h * 360, s * 100, l * 100)

def color_distance(color1: str, color2: str) -> float:
    """è¨ˆç®—å…©å€‹é¡è‰²çš„è·é›¢ï¼ˆæ­å¹¾é‡Œå¾—è·é›¢ï¼‰"""
    try:
        rgb1 = hex_to_rgb(color1)
        rgb2 = hex_to_rgb(color2)
        return sum((a - b) ** 2 for a, b in zip(rgb1, rgb2)) ** 0.5
    except:
        return float('inf')

def normalize_color(color: str) -> str:
    """æ­£è¦åŒ–é¡è‰²æ ¼å¼ç‚ºå¤§å¯« HEX"""
    color = color.strip().lower()
    # ç§»é™¤å¯èƒ½çš„ç©ºæ ¼
    color = color.replace(' ', '')
    
    # HEX æ ¼å¼
    if color.startswith('#'):
        hex_part = color[1:]
        if len(hex_part) == 3:
            hex_part = ''.join([c*2 for c in hex_part])
        return '#' + hex_part.upper()
    
    # RGB/RGBA æ ¼å¼
    rgb_match = re.match(r'rgba?\((\d+),\s*(\d+),\s*(\d+)', color)
    if rgb_match:
        r, g, b = map(int, rgb_match.groups())
        return f"#{r:02X}{g:02X}{b:02X}"
    
    return color

def is_third_party_embed(context: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦ç‚ºç¬¬ä¸‰æ–¹åµŒå…¥ä»£ç¢¼ï¼ˆå¦‚ Instagram embedï¼‰"""
    third_party_indicators = [
        'instagram-media',
        'data-instgrm',
        'instagram.com',
        'facebook.com',
        'twitter.com',
        'youtube.com',
        'embed',
        'iframe',
    ]
    context_lower = context.lower()
    return any(indicator in context_lower for indicator in third_party_indicators)

def is_css_variable_definition(context: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦ç‚º CSS è®Šæ•¸å®šç¾©ï¼ˆé€™äº›æ˜¯ token å®šç¾©æœ¬èº«ï¼Œä¸æ‡‰è¢«æ¨™è¨˜ç‚ºæœªå®šç¾©ï¼‰"""
    # CSS è®Šæ•¸å®šç¾©æ ¼å¼ï¼š--color-xxx: #xxxxxx;
    css_var_patterns = [
        r'--color-[^:]+:\s*#',
        r'--color-[^:]+:\s*var\(',
    ]
    for pattern in css_var_patterns:
        if re.search(pattern, context, re.IGNORECASE):
            return True
    return False

def extract_colors_from_text(text: str) -> List[Dict[str, Any]]:
    """å¾æ–‡å­—ä¸­æå–æ‰€æœ‰é¡è‰²å€¼ï¼Œæ’é™¤ç¬¬ä¸‰æ–¹åµŒå…¥ä»£ç¢¼"""
    colors = []
    
    # HEX é¡è‰² (#fff, #ffffff, #FFF)
    hex_pattern = r'#([0-9a-fA-F]{3}|[0-9a-fA-F]{6})\b'
    for match in re.finditer(hex_pattern, text):
        context = text[max(0, match.start()-50):match.end()+50]
        # æ’é™¤ç¬¬ä¸‰æ–¹åµŒå…¥ä»£ç¢¼
        if is_third_party_embed(context):
            continue
        # æ’é™¤ CSS è®Šæ•¸å®šç¾©
        if is_css_variable_definition(context):
            continue
        color = normalize_color(match.group(0))
        colors.append({
            'value': color,
            'type': 'hex',
            'line': text[:match.start()].count('\n') + 1,
            'context': context
        })
    
    # RGB/RGBA é¡è‰²
    rgb_pattern = r'rgba?\((\d+),\s*(\d+),\s*(\d+)(?:,\s*[\d.]+)?\)'
    for match in re.finditer(rgb_pattern, text):
        context = text[max(0, match.start()-50):match.end()+50]
        # æ’é™¤ç¬¬ä¸‰æ–¹åµŒå…¥ä»£ç¢¼
        if is_third_party_embed(context):
            continue
        # æ’é™¤ CSS è®Šæ•¸å®šç¾©
        if is_css_variable_definition(context):
            continue
        color = normalize_color(match.group(0))
        colors.append({
            'value': color,
            'type': 'rgb',
            'line': text[:match.start()].count('\n') + 1,
            'context': context
        })
    
    # HSL/HSLA é¡è‰²
    hsl_pattern = r'hsla?\((\d+),\s*(\d+)%,\s*(\d+)%'
    for match in re.finditer(hsl_pattern, text):
        context = text[max(0, match.start()-50):match.end()+50]
        if is_third_party_embed(context):
            continue
        colors.append({
            'value': match.group(0),
            'type': 'hsl',
            'line': text[:match.start()].count('\n') + 1,
            'context': context
        })
    
    # å‘½åé¡è‰²ï¼ˆwhite, black, gray ç­‰ï¼‰
    named_colors = ['white', 'black', 'gray', 'grey', 'red', 'blue', 'green', 'yellow', 'orange', 'purple', 'pink', 'brown']
    for color_name in named_colors:
        pattern = rf'\b{color_name}\b'
        for match in re.finditer(pattern, text, re.IGNORECASE):
            # é¿å…åŒ¹é…åˆ°é¡åä¸­çš„é¡è‰²ï¼ˆå¦‚ text-whiteï¼‰
            context_before = text[max(0, match.start()-10):match.start()]
            if ':' in context_before or '=' in context_before:
                context = text[max(0, match.start()-50):match.end()+50]
                if is_third_party_embed(context):
                    continue
                colors.append({
                    'value': color_name.lower(),
                    'type': 'named',
                    'line': text[:match.start()].count('\n') + 1,
                    'context': context
                })
    
    return colors

def extract_spacing_values(text: str) -> List[Dict[str, Any]]:
    """æå–é–“è·å€¼ï¼ˆmargin, padding, gapï¼‰"""
    spacing_values = []
    
    # margin/padding å€¼
    spacing_pattern = r'(?:margin|padding|gap|row-gap|column-gap)[:\s]+([\d.]+)(px|rem|em|%)'
    for match in re.finditer(spacing_pattern, text, re.IGNORECASE):
        spacing_values.append({
            'value': match.group(1) + match.group(2),
            'property': match.group(0).split(':')[0].strip(),
            'line': text[:match.start()].count('\n') + 1,
        })
    
    # Tailwind spacing é¡åï¼ˆp-4, m-8, gap-6 ç­‰ï¼‰
    tw_spacing_pattern = r'\b(p|m|gap|space-[xy])-(\d+)\b'
    for match in re.finditer(tw_spacing_pattern, text):
        spacing_values.append({
            'value': match.group(2),
            'property': f"tailwind-{match.group(1)}",
            'line': text[:match.start()].count('\n') + 1,
        })
    
    return spacing_values

def extract_typography_values(text: str) -> List[Dict[str, Any]]:
    """æå–å­—é«”ç›¸é—œå€¼ï¼Œæ’é™¤ç¬¬ä¸‰æ–¹åµŒå…¥ä»£ç¢¼"""
    typography = []
    
    # font-size
    font_size_pattern = r'font-size[:\s]+([\d.]+)(px|rem|em|%)'
    for match in re.finditer(font_size_pattern, text, re.IGNORECASE):
        context = text[max(0, match.start()-50):match.end()+50]
        # æ’é™¤ç¬¬ä¸‰æ–¹åµŒå…¥ä»£ç¢¼
        if is_third_party_embed(context):
            continue
        typography.append({
            'property': 'font-size',
            'value': match.group(1) + match.group(2),
            'line': text[:match.start()].count('\n') + 1,
        })
    
    # font-weight
    font_weight_pattern = r'font-weight[:\s]+(\d+|normal|bold|medium|semibold)'
    for match in re.finditer(font_weight_pattern, text, re.IGNORECASE):
        typography.append({
            'property': 'font-weight',
            'value': match.group(1),
            'line': text[:match.start()].count('\n') + 1,
        })
    
    # line-height
    line_height_pattern = r'line-height[:\s]+([\d.]+|normal|tight|relaxed|loose)'
    for match in re.finditer(line_height_pattern, text, re.IGNORECASE):
        typography.append({
            'property': 'line-height',
            'value': match.group(1),
            'line': text[:match.start()].count('\n') + 1,
        })
    
    # font-family
    font_family_pattern = r'font-family[:\s]+([^;]+)'
    for match in re.finditer(font_family_pattern, text, re.IGNORECASE):
        typography.append({
            'property': 'font-family',
            'value': match.group(1).strip(),
            'line': text[:match.start()].count('\n') + 1,
        })
    
    return typography

def extract_border_radius(text: str) -> List[Dict[str, Any]]:
    """æå–åœ“è§’å€¼"""
    radius_values = []
    
    # border-radius
    radius_pattern = r'border-radius[:\s]+([\d.]+)(px|rem|em|%)'
    for match in re.finditer(radius_pattern, text, re.IGNORECASE):
        radius_values.append({
            'value': match.group(1) + match.group(2),
            'line': text[:match.start()].count('\n') + 1,
        })
    
    # rounded-* Tailwind é¡å
    rounded_pattern = r'\brounded(-(?:sm|md|lg|xl|full|none))?\b'
    for match in re.finditer(rounded_pattern, text):
        radius_values.append({
            'value': match.group(1) if match.group(1) else 'default',
            'type': 'tailwind',
            'line': text[:match.start()].count('\n') + 1,
        })
    
    return radius_values

def extract_shadows(text: str) -> List[Dict[str, Any]]:
    """æå–é™°å½±å€¼"""
    shadows = []
    
    # box-shadow
    shadow_pattern = r'box-shadow[:\s]+([^;]+)'
    for match in re.finditer(shadow_pattern, text, re.IGNORECASE):
        shadows.append({
            'value': match.group(1).strip(),
            'line': text[:match.start()].count('\n') + 1,
        })
    
    return shadows

def extract_ui_components(text: str) -> Dict[str, List[Dict[str, Any]]]:
    """æå– UI å…ƒä»¶ç›¸é—œçš„é¡åå’Œæ¨£å¼"""
    components = defaultdict(list)
    
    # Button ç›¸é—œ
    button_patterns = [
        r'\b(btn|button)[-\w]*',
        r'bg-trust-\d+|bg-sand-\d+.*rounded.*px-\d+.*py-\d+',
    ]
    for pattern in button_patterns:
        for match in re.finditer(pattern, text, re.IGNORECASE):
            components['button'].append({
                'classes': match.group(0),
                'line': text[:match.start()].count('\n') + 1,
            })
    
    # Card ç›¸é—œ
    card_patterns = [
        r'\b(card|bento-card)[-\w]*',
    ]
    for pattern in card_patterns:
        for match in re.finditer(pattern, text, re.IGNORECASE):
            components['card'].append({
                'classes': match.group(0),
                'line': text[:match.start()].count('\n') + 1,
            })
    
    return dict(components)

def load_design_tokens():
    """å¾ tailwind.config.js å’Œ main.css è¼‰å…¥è¨­è¨ˆ token"""
    # é€™è£¡ç°¡åŒ–è™•ç†ï¼Œå¯¦éš›æ‡‰è©²è§£æ JS å’Œ CSS æª”æ¡ˆ
    # å¾å·²çŸ¥çš„ tailwind.config.js çµæ§‹æå–
    tokens = {
        'colors': {
            'trust-50': '#F0F4FF',
            'trust-100': '#E0E7FF',
            'trust-200': '#C7D2FE',
            'trust-500': '#6366F1',
            'trust-600': '#4F46E5',
            'trust-700': '#4338CA',
            'trust-800': '#1E3A8A',
            'trust-900': '#0F172A',
            'trust-950': '#020617',
            'sand-50': '#FDFBF7',
            'sand-100': '#F7F4EF',
            'sand-200': '#E2DCD3',
            'sand-300': '#D6CCC2',
            'white': '#fff',
            'black': '#000',
        },
        'spacing': {
            '1': '0.25rem',  # 4px
            '2': '0.5rem',   # 8px
            '3': '0.75rem',  # 12px
            '4': '1rem',     # 16px
            '5': '1.25rem',  # 20px
            '6': '1.5rem',   # 24px
            '8': '2rem',     # 32px
            '10': '3rem',    # 48px
            '12': '4rem',    # 64px
        },
        'fontSize': {
            'xs': '0.75rem',   # 12px
            'sm': '0.875rem',  # 14px
            'base': '1rem',    # 16px
            'lg': '1.125rem',  # 18px
            'xl': '1.25rem',   # 20px
            '2xl': '1.5rem',   # 24px
            '3xl': '1.875rem', # 30px
            '4xl': '2.25rem',  # 36px
        },
        'borderRadius': {
            'sm': '4px',
            'md': '8px',
            'lg': '12px',
            'xl': '20px',
            'full': '9999px',
        },
    }
    return tokens

def scan_project():
    """æƒææ•´å€‹å°ˆæ¡ˆ"""
    results = {
        'colors': [],
        'spacing': [],
        'typography': [],
        'borderRadius': [],
        'shadows': [],
        'components': defaultdict(list),
        'files_scanned': [],
    }
    
    design_tokens = load_design_tokens()
    
    # æƒææ‰€æœ‰ç›¸é—œæª”æ¡ˆ
    for file_path in SRC_DIR.rglob('*'):
        if file_path.suffix in SCAN_EXTENSIONS:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    relative_path = file_path.relative_to(PROJECT_ROOT)
                    results['files_scanned'].append(str(relative_path))
                    
                    # æå–å„ç¨®å€¼
                    results['colors'].extend([
                        {**c, 'file': str(relative_path)} 
                        for c in extract_colors_from_text(content)
                    ])
                    results['spacing'].extend([
                        {**s, 'file': str(relative_path)} 
                        for s in extract_spacing_values(content)
                    ])
                    results['typography'].extend([
                        {**t, 'file': str(relative_path)} 
                        for t in extract_typography_values(content)
                    ])
                    results['borderRadius'].extend([
                        {**r, 'file': str(relative_path)} 
                        for r in extract_border_radius(content)
                    ])
                    results['shadows'].extend([
                        {**s, 'file': str(relative_path)} 
                        for s in extract_shadows(content)
                    ])
                    
                    # UI å…ƒä»¶
                    components = extract_ui_components(content)
                    for comp_type, comp_list in components.items():
                        results['components'][comp_type].extend([
                            {**c, 'file': str(relative_path)} 
                            for c in comp_list
                        ])
            except Exception as e:
                print(f"Error scanning {file_path}: {e}")
    
    return results, design_tokens

def analyze_colors(colors: List[Dict], tokens: Dict) -> Dict[str, Any]:
    """åˆ†æé¡è‰²ä¸€è‡´æ€§"""
    # çµ±è¨ˆé¡è‰²ä½¿ç”¨é »ç‡
    color_counter = Counter()
    for color in colors:
        if color['value'].startswith('#'):
            color_counter[color['value']] += 1
    
    # æ‰¾å‡ºæœªå®šç¾©åœ¨ token ä¸­çš„é¡è‰²
    token_colors = set(tokens['colors'].values())
    undefined_colors = []
    for color_value, count in color_counter.items():
        if color_value not in token_colors:
            # æª¢æŸ¥æ˜¯å¦æœ‰è¿‘ä¼¼é¡è‰²ï¼ˆè‰²å·® < 10ï¼‰
            is_similar = False
            for token_color in token_colors:
                if token_color.startswith('#'):
                    if color_distance(color_value, token_color) < 10:
                        is_similar = True
                        break
            if not is_similar:
                undefined_colors.append({
                    'color': color_value,
                    'count': count,
                })
    
    # èšé¡è¿‘ä¼¼é¡è‰²
    color_clusters = defaultdict(list)
    for color_value, count in color_counter.items():
        if color_value.startswith('#'):
            clustered = False
            for cluster_center in color_clusters.keys():
                if color_distance(color_value, cluster_center) < 5:
                    color_clusters[cluster_center].append((color_value, count))
                    clustered = True
                    break
            if not clustered:
                color_clusters[color_value] = [(color_value, count)]
    
    return {
        'total_colors': len(color_counter),
        'unique_colors': len(color_clusters),
        'undefined_colors': sorted(undefined_colors, key=lambda x: x['count'], reverse=True)[:20],
        'most_used': color_counter.most_common(10),
        'clusters': {k: v for k, v in list(color_clusters.items())[:10]},
    }

def analyze_spacing(spacing: List[Dict], tokens: Dict) -> Dict[str, Any]:
    """åˆ†æé–“è·ä¸€è‡´æ€§"""
    spacing_values = Counter()
    for s in spacing:
        spacing_values[s['value']] += 1
    
    # æª¢æŸ¥æ˜¯å¦ç¬¦åˆ 4px ç¯€å¥
    non_standard_spacing = []
    for value, count in spacing_values.items():
        if isinstance(value, str) and value.replace('.', '').isdigit():
            num_value = float(value)
            # æª¢æŸ¥æ˜¯å¦ç‚º 4 çš„å€æ•¸ï¼ˆè€ƒæ…® rem è½‰æ›ï¼‰
            if num_value % 4 != 0 and num_value not in [0.25, 0.5, 0.75, 1, 1.25, 1.5, 2, 3, 4]:
                non_standard_spacing.append({
                    'value': value,
                    'count': count,
                })
    
    return {
        'total_spacing_values': len(spacing),
        'unique_values': len(spacing_values),
        'most_used': spacing_values.most_common(15),
        'non_standard': sorted(non_standard_spacing, key=lambda x: x['count'], reverse=True)[:15],
    }

def analyze_typography(typography: List[Dict], tokens: Dict) -> Dict[str, Any]:
    """åˆ†æå­—é«”ä¸€è‡´æ€§"""
    font_sizes = Counter()
    font_weights = Counter()
    line_heights = Counter()
    
    for t in typography:
        if t['property'] == 'font-size':
            font_sizes[t['value']] += 1
        elif t['property'] == 'font-weight':
            font_weights[t['value']] += 1
        elif t['property'] == 'line-height':
            line_heights[t['value']] += 1
    
    # æ‰¾å‡ºæœªå®šç¾©çš„å­—é«”å¤§å°
    token_sizes = set(tokens['fontSize'].values())
    undefined_sizes = []
    for size, count in font_sizes.items():
        if size not in token_sizes:
            undefined_sizes.append({
                'size': size,
                'count': count,
            })
    
    return {
        'font_sizes': {
            'total': len(font_sizes),
            'unique': len(font_sizes),
            'most_used': font_sizes.most_common(10),
            'undefined': sorted(undefined_sizes, key=lambda x: x['count'], reverse=True)[:10],
        },
        'font_weights': {
            'total': len(font_weights),
            'most_used': font_weights.most_common(10),
        },
        'line_heights': {
            'total': len(line_heights),
            'most_used': line_heights.most_common(10),
        },
    }

def calculate_consistency_score(results: Dict, tokens: Dict) -> Dict[str, Any]:
    """è¨ˆç®—ä¸€è‡´æ€§åˆ†æ•¸"""
    color_analysis = analyze_colors(results['colors'], tokens)
    spacing_analysis = analyze_spacing(results['spacing'], tokens)
    typography_analysis = analyze_typography(results['typography'], tokens)
    
    # è¨ˆç®—å„å­ç³»çµ±åˆ†æ•¸ï¼ˆ0-100ï¼‰
    # é¡è‰²åˆ†æ•¸ï¼šåŸºæ–¼æœªå®šç¾©é¡è‰²æ¯”ä¾‹
    total_color_usage = sum(count for _, count in color_analysis['most_used'])
    undefined_color_usage = sum(c['count'] for c in color_analysis['undefined_colors'])
    color_score = max(0, 100 - (undefined_color_usage / max(total_color_usage, 1) * 100))
    
    # é–“è·åˆ†æ•¸ï¼šåŸºæ–¼éæ¨™æº–é–“è·æ¯”ä¾‹
    total_spacing = len(results['spacing'])
    non_standard_count = len(spacing_analysis['non_standard'])
    spacing_score = max(0, 100 - (non_standard_count / max(total_spacing, 1) * 100))
    
    # å­—é«”åˆ†æ•¸ï¼šåŸºæ–¼æœªå®šç¾©å­—é«”å¤§å°æ¯”ä¾‹
    total_font_sizes = sum(count for _, count in typography_analysis['font_sizes']['most_used'])
    undefined_font_usage = sum(c['count'] for c in typography_analysis['font_sizes']['undefined'])
    typography_score = max(0, 100 - (undefined_font_usage / max(total_font_sizes, 1) * 100))
    
    # ç¸½åˆ†ï¼ˆåŠ æ¬Šå¹³å‡ï¼‰
    overall_score = (color_score * 0.3 + spacing_score * 0.3 + typography_score * 0.4)
    
    return {
        'overall': round(overall_score, 1),
        'color': round(color_score, 1),
        'spacing': round(spacing_score, 1),
        'typography': round(typography_score, 1),
        'components': 75.0,  # æš«æ™‚å›ºå®šå€¼ï¼Œéœ€è¦æ›´æ·±å…¥åˆ†æ
    }

def generate_report(results: Dict, tokens: Dict) -> str:
    """ç”Ÿæˆç¨½æ ¸å ±å‘Š"""
    score = calculate_consistency_score(results, tokens)
    color_analysis = analyze_colors(results['colors'], tokens)
    spacing_analysis = analyze_spacing(results['spacing'], tokens)
    typography_analysis = analyze_typography(results['typography'], tokens)
    
    # æ ¼å¼åŒ–æ—¥æœŸ
    audit_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    report_timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    
    report = f"""# è¨­è¨ˆç³»çµ±ä¸€è‡´æ€§ç¨½æ ¸å ±å‘Š

## ğŸ“Š åŸ·è¡Œæ‘˜è¦

**ç¨½æ ¸æ—¥æœŸ**: {audit_date}
**æƒææª”æ¡ˆæ•¸**: {len(results['files_scanned'])}
**ç¸½é«”ä¸€è‡´æ€§åˆ†æ•¸**: **{score['overall']}/100**

### å„å­ç³»çµ±åˆ†æ•¸

| å­ç³»çµ± | åˆ†æ•¸ | ç‹€æ…‹ |
|--------|------|------|
| é¡è‰²ç³»çµ± (Color) | {score['color']}/100 | {'âœ… è‰¯å¥½' if score['color'] >= 80 else 'âš ï¸ éœ€æ”¹é€²' if score['color'] >= 60 else 'âŒ åš´é‡'} |
| é–“è·ç³»çµ± (Spacing) | {score['spacing']}/100 | {'âœ… è‰¯å¥½' if score['spacing'] >= 80 else 'âš ï¸ éœ€æ”¹é€²' if score['spacing'] >= 60 else 'âŒ åš´é‡'} |
| å­—é«”ç³»çµ± (Typography) | {score['typography']}/100 | {'âœ… è‰¯å¥½' if score['typography'] >= 80 else 'âš ï¸ éœ€æ”¹é€²' if score['typography'] >= 60 else 'âŒ åš´é‡'} |
| å…ƒä»¶ç³»çµ± (Components) | {score['components']}/100 | {'âœ… è‰¯å¥½' if score['components'] >= 80 else 'âš ï¸ éœ€æ”¹é€²' if score['components'] >= 60 else 'âŒ åš´é‡'} |

---

## ğŸŸ¦ 1. é¡è‰²ç³»çµ±ä¸€è‡´æ€§åˆ†æ

### çµ±è¨ˆæ•¸æ“š

- **ç¸½é¡è‰²ä½¿ç”¨æ¬¡æ•¸**: {sum(count for _, count in color_analysis['most_used'])}
- **å”¯ä¸€é¡è‰²æ•¸é‡**: {color_analysis['unique_colors']}
- **æœªå®šç¾©æ–¼ Token çš„é¡è‰²**: {len(color_analysis['undefined_colors'])}

### æœ€å¸¸ä½¿ç”¨çš„é¡è‰²ï¼ˆTop 10ï¼‰

"""
    
    for i, (color, count) in enumerate(color_analysis['most_used'][:10], 1):
        report += f"{i}. `{color}` - ä½¿ç”¨ {count} æ¬¡\n"
    
    report += f"""
### âš ï¸ æœªå®šç¾©æ–¼è¨­è¨ˆ Token çš„é¡è‰²ï¼ˆéœ€è™•ç†ï¼‰

"""
    
    if color_analysis['undefined_colors']:
        for i, item in enumerate(color_analysis['undefined_colors'][:10], 1):
            report += f"{i}. `{item['color']}` - ä½¿ç”¨ {item['count']} æ¬¡\n"
    else:
        report += "âœ… æ‰€æœ‰é¡è‰²éƒ½å·²å®šç¾©æ–¼è¨­è¨ˆ Token\n"
    
    report += f"""
### é¡è‰²èšé¡åˆ†æ

ç™¼ç¾ {len(color_analysis['clusters'])} å€‹ä¸»è¦é¡è‰²ç¾¤çµ„ã€‚å»ºè­°å°‡è¿‘ä¼¼é¡è‰²çµ±ä¸€ç‚ºå–®ä¸€ tokenã€‚

---

## ğŸŸ¨ 2. é–“è·ç³»çµ±ä¸€è‡´æ€§åˆ†æ

### çµ±è¨ˆæ•¸æ“š

- **ç¸½é–“è·ä½¿ç”¨æ¬¡æ•¸**: {spacing_analysis['total_spacing_values']}
- **å”¯ä¸€é–“è·å€¼**: {spacing_analysis['unique_values']}
- **éæ¨™æº–é–“è·å€¼**: {len(spacing_analysis['non_standard'])}

### æœ€å¸¸ä½¿ç”¨çš„é–“è·å€¼ï¼ˆTop 15ï¼‰

"""
    
    for i, (value, count) in enumerate(spacing_analysis['most_used'][:15], 1):
        report += f"{i}. `{value}` - ä½¿ç”¨ {count} æ¬¡\n"
    
    report += f"""
### âš ï¸ éæ¨™æº–é–“è·å€¼ï¼ˆä¸ç¬¦åˆ 4px ç¯€å¥ï¼‰

"""
    
    if spacing_analysis['non_standard']:
        for i, item in enumerate(spacing_analysis['non_standard'][:15], 1):
            report += f"{i}. `{item['value']}` - ä½¿ç”¨ {item['count']} æ¬¡\n"
    else:
        report += "âœ… æ‰€æœ‰é–“è·å€¼éƒ½ç¬¦åˆæ¨™æº–ç¯€å¥\n"
    
    report += f"""
---

## ğŸŸ© 3. å­—é«”èˆ‡æ’ç‰ˆç³»çµ±åˆ†æ

### å­—é«”å¤§å° (Font Size)

- **ç¸½ä½¿ç”¨æ¬¡æ•¸**: {sum(count for _, count in typography_analysis['font_sizes']['most_used'])}
- **å”¯ä¸€å­—é«”å¤§å°**: {typography_analysis['font_sizes']['unique']}
- **æœªå®šç¾©æ–¼ Token**: {len(typography_analysis['font_sizes']['undefined'])}

#### æœ€å¸¸ä½¿ç”¨çš„å­—é«”å¤§å°

"""
    
    for i, (size, count) in enumerate(typography_analysis['font_sizes']['most_used'][:10], 1):
        report += f"{i}. `{size}` - ä½¿ç”¨ {count} æ¬¡\n"
    
    report += f"""
#### âš ï¸ æœªå®šç¾©çš„å­—é«”å¤§å°

"""
    
    if typography_analysis['font_sizes']['undefined']:
        for i, item in enumerate(typography_analysis['font_sizes']['undefined'][:10], 1):
            report += f"{i}. `{item['size']}` - ä½¿ç”¨ {item['count']} æ¬¡\n"
    else:
        report += "âœ… æ‰€æœ‰å­—é«”å¤§å°éƒ½å·²å®šç¾©æ–¼ Token\n"
    
    report += f"""
### å­—é«”ç²—ç´° (Font Weight)

#### æœ€å¸¸ä½¿ç”¨çš„å­—é«”ç²—ç´°

"""
    
    for i, (weight, count) in enumerate(typography_analysis['font_weights']['most_used'][:10], 1):
        report += f"{i}. `{weight}` - ä½¿ç”¨ {count} æ¬¡\n"
    
    report += f"""
### è¡Œé«˜ (Line Height)

#### æœ€å¸¸ä½¿ç”¨çš„è¡Œé«˜

"""
    
    for i, (lh, count) in enumerate(typography_analysis['line_heights']['most_used'][:10], 1):
        report += f"{i}. `{lh}` - ä½¿ç”¨ {count} æ¬¡\n"
    
    report += f"""
---

## ğŸŸª 4. åœ“è§’ã€é™°å½±ã€é‚Šæ¡†åˆ†æ

### åœ“è§’ (Border Radius)

- **ç¸½ä½¿ç”¨æ¬¡æ•¸**: {len(results['borderRadius'])}
- **å”¯ä¸€å€¼**: {len(set(r.get('value', '') for r in results['borderRadius']))}

### é™°å½± (Box Shadow)

- **ç¸½ä½¿ç”¨æ¬¡æ•¸**: {len(results['shadows'])}
- **å”¯ä¸€å€¼**: {len(set(s.get('value', '') for s in results['shadows']))}

---

## ğŸŸ¥ 5. UI å…ƒä»¶ä¸€è‡´æ€§åˆ†æ

### å…ƒä»¶çµ±è¨ˆ

"""
    
    for comp_type, comp_list in results['components'].items():
        report += f"- **{comp_type.capitalize()}**: {len(comp_list)} è™•ä½¿ç”¨\n"
    
    report += f"""
### å…ƒä»¶æ¨£å¼é‡è¤‡åˆ†æ

å»ºè­°æª¢æŸ¥ä»¥ä¸‹å…ƒä»¶æ˜¯å¦æœ‰çµ±ä¸€çš„ variant/size/state å®šç¾©ï¼š

"""
    
    for comp_type, comp_list in results['components'].items():
        if comp_list:
            unique_classes = set(c.get('classes', '') for c in comp_list)
            report += f"- **{comp_type}**: {len(unique_classes)} ç¨®ä¸åŒé¡åçµ„åˆ\n"
    
    report += f"""
---

## ğŸ” å‰ 10 å¤§ä¸€è‡´æ€§ç ´å£ä¾†æº

### 1. æœªå®šç¾©é¡è‰²
"""
    
    if color_analysis['undefined_colors']:
        for i, item in enumerate(color_analysis['undefined_colors'][:5], 1):
            report += f"   - `{item['color']}` ä½¿ç”¨ {item['count']} æ¬¡\n"
    
    report += f"""
### 2. éæ¨™æº–é–“è·
"""
    
    if spacing_analysis['non_standard']:
        for i, item in enumerate(spacing_analysis['non_standard'][:5], 1):
            report += f"   - `{item['value']}` ä½¿ç”¨ {item['count']} æ¬¡\n"
    
    report += f"""
### 3. æœªå®šç¾©å­—é«”å¤§å°
"""
    
    if typography_analysis['font_sizes']['undefined']:
        for i, item in enumerate(typography_analysis['font_sizes']['undefined'][:5], 1):
            report += f"   - `{item['size']}` ä½¿ç”¨ {item['count']} æ¬¡\n"
    
    report += f"""
---

## ğŸ“‹ æŠ€è¡“è² å‚µåˆ†é¡

### ğŸŸ¢ å¿«é€Ÿå¯ä¿® (Quick Wins)

1. **çµ±ä¸€è¿‘ä¼¼é¡è‰²**
   - å°‡è‰²å·® < 5 çš„é¡è‰²åˆä½µç‚ºå–®ä¸€ token
   - é ä¼°æ™‚é–“: 2-4 å°æ™‚

2. **ç§»é™¤æœªä½¿ç”¨çš„ Legacy Token**
   - æ¸…ç† tailwind.config.js ä¸­æ¨™è¨˜ç‚º "Deprecated" çš„é¡è‰²
   - é ä¼°æ™‚é–“: 1-2 å°æ™‚

3. **æ¨™æº–åŒ–é–“è·å€¼**
   - å°‡é 4px å€æ•¸çš„é–“è·å€¼èª¿æ•´ç‚ºæ¨™æº–å€¼
   - é ä¼°æ™‚é–“: 3-5 å°æ™‚

### ğŸŸ¡ ä¸­æœŸæ•´ç† (Medium-term)

1. **å»ºç«‹å®Œæ•´çš„å…ƒä»¶ Variant ç³»çµ±**
   - ç‚º Buttonã€Card ç­‰å…ƒä»¶å®šç¾©æ˜ç¢ºçš„ variant/size/state
   - é ä¼°æ™‚é–“: 1-2 å¤©

2. **çµ±ä¸€å­—é«”å¤§å°éšå±¤**
   - å»ºç«‹å®Œæ•´çš„å­—ç´š scaleï¼Œç§»é™¤éš¨æ„æ•¸å€¼
   - é ä¼°æ™‚é–“: 4-6 å°æ™‚

3. **é™°å½±ç³»çµ±æ¨™æº–åŒ–**
   - å®šç¾©æœ‰é™çš„é™°å½±å±¤ç´šï¼ˆsm/md/lg/xlï¼‰
   - é ä¼°æ™‚é–“: 2-3 å°æ™‚

### ğŸ”´ æ¶æ§‹ç´šé‡æ§‹ (Architecture)

1. **è¨­è¨ˆ Token é·ç§»ç­–ç•¥**
   - å¾ Tailwind config é·ç§»åˆ° CSS Variables
   - å»ºç«‹å–®ä¸€ä¾†æºçš„è¨­è¨ˆ token ç³»çµ±
   - é ä¼°æ™‚é–“: 3-5 å¤©

2. **å…ƒä»¶æŠ½è±¡å±¤é‡æ§‹**
   - å»ºç«‹å¯é‡ç”¨çš„å…ƒä»¶åº«ï¼ˆå¦‚ Nunjucks macrosï¼‰
   - æ¸›å°‘é‡è¤‡çš„æ¨£å¼å®šç¾©
   - é ä¼°æ™‚é–“: 5-7 å¤©

---

## âœ… å…·é«”å¯åŸ·è¡Œçš„ä¸‹ä¸€æ­¥å»ºè­°

### ç«‹å³åŸ·è¡Œï¼ˆæœ¬é€±ï¼‰

1. âœ… **å¯©æŸ¥ä¸¦åˆä½µè¿‘ä¼¼é¡è‰²**
   ```bash
   # å»ºè­°å„ªå…ˆè™•ç†ä½¿ç”¨é »ç‡ > 5 æ¬¡çš„æœªå®šç¾©é¡è‰²
   ```

2. âœ… **æ¸…ç† Deprecated Token**
   - ç§»é™¤ tailwind.config.js ä¸­æ¨™è¨˜ç‚º "Deprecated" çš„é¡è‰²å®šç¾©
   - æ›´æ–°æ‰€æœ‰å¼•ç”¨ç‚ºæ–°çš„ token åç¨±

3. âœ… **å»ºç«‹é–“è·ä½¿ç”¨æŒ‡å—**
   - æ–‡ä»¶åŒ–æ¨™æº–é–“è·å€¼ï¼ˆ4px ç¯€å¥ï¼‰
   - åœ¨ code review ä¸­æª¢æŸ¥éæ¨™æº–é–“è·

### çŸ­æœŸåŸ·è¡Œï¼ˆ2-4 é€±ï¼‰

1. âœ… **å»ºç«‹å…ƒä»¶ Variant ç³»çµ±**
   - å®šç¾© Button çš„ variant: primary, secondary, ghost
   - å®šç¾© Card çš„ variant: default, elevated, bordered

2. âœ… **çµ±ä¸€å­—é«”éšå±¤**
   - å»ºç«‹å®Œæ•´çš„å­—ç´š scaleï¼ˆxs, sm, base, lg, xl, 2xl, 3xl, 4xlï¼‰
   - ç§»é™¤æ‰€æœ‰ç¡¬ç·¨ç¢¼çš„å­—é«”å¤§å°

3. âœ… **å»ºç«‹è¨­è¨ˆç³»çµ±æ–‡ä»¶**
   - æ–‡ä»¶åŒ–æ‰€æœ‰è¨­è¨ˆ token
   - å»ºç«‹å…ƒä»¶ä½¿ç”¨æŒ‡å—

### é•·æœŸåŸ·è¡Œï¼ˆ1-3 å€‹æœˆï¼‰

1. âœ… **é·ç§»åˆ° CSS Variables ç‚ºä¸»çš„ Token ç³»çµ±**
   - å°‡ Tailwind config ä¸­çš„ token é·ç§»åˆ° CSS Variables
   - å»ºç«‹å–®ä¸€ä¾†æºçš„è¨­è¨ˆç³»çµ±

2. âœ… **å»ºç«‹å…ƒä»¶åº«**
   - ä½¿ç”¨ Nunjucks macros å»ºç«‹å¯é‡ç”¨å…ƒä»¶
   - æ¸›å°‘é‡è¤‡çš„ HTML/CSS ä»£ç¢¼

---

## ğŸ“ˆ æ”¹é€²è¿½è¹¤

å»ºè­°å»ºç«‹ä»¥ä¸‹è¿½è¹¤æ©Ÿåˆ¶ï¼š

1. **å®šæœŸç¨½æ ¸**
   - æ¯æœˆåŸ·è¡Œä¸€æ¬¡è¨­è¨ˆç³»çµ±ä¸€è‡´æ€§æƒæ
   - è¿½è¹¤ä¸€è‡´æ€§åˆ†æ•¸è®ŠåŒ–

2. **Code Review æª¢æŸ¥æ¸…å–®**
   - [ ] æ˜¯å¦ä½¿ç”¨è¨­è¨ˆ token è€Œéç¡¬ç·¨ç¢¼å€¼ï¼Ÿ
   - [ ] é–“è·æ˜¯å¦ç¬¦åˆ 4px ç¯€å¥ï¼Ÿ
   - [ ] é¡è‰²æ˜¯å¦ä¾†è‡ªè¨­è¨ˆç³»çµ±ï¼Ÿ
   - [ ] å…ƒä»¶æ˜¯å¦ä½¿ç”¨çµ±ä¸€çš„ variantï¼Ÿ

3. **è‡ªå‹•åŒ–æª¢æŸ¥**
   - è€ƒæ…®å»ºç«‹ ESLint/Prettier è¦å‰‡æª¢æŸ¥ç¡¬ç·¨ç¢¼æ¨£å¼
   - åœ¨ CI/CD ä¸­æ•´åˆè¨­è¨ˆç³»çµ±æª¢æŸ¥

---

## ğŸ“ é™„éŒ„

### æƒæçš„æª”æ¡ˆæ¸…å–®

å…±æƒæ {len(results['files_scanned'])} å€‹æª”æ¡ˆï¼š

"""
    
    for file_path in sorted(results['files_scanned'])[:50]:  # åªé¡¯ç¤ºå‰ 50 å€‹
        report += f"- `{file_path}`\n"
    
    if len(results['files_scanned']) > 50:
        report += f"\n... é‚„æœ‰ {len(results['files_scanned']) - 50} å€‹æª”æ¡ˆ\n"
    
    report += f"""
### è¨­è¨ˆ Token åƒè€ƒ

ç•¶å‰è¨­è¨ˆç³»çµ±å®šç¾©æ–¼ï¼š
- `tailwind.config.js` - Tailwind é…ç½®
- `src/assets/css/main.css` - CSS Variables

å»ºè­°å»ºç«‹ç¨ç«‹çš„è¨­è¨ˆ token æ–‡ä»¶ï¼ˆJSON/YAMLï¼‰ä½œç‚ºå–®ä¸€ä¾†æºã€‚

---

**å ±å‘Šç”Ÿæˆæ™‚é–“**: {report_timestamp}
**ç¨½æ ¸å·¥å…·ç‰ˆæœ¬**: 1.0.0

---

## ğŸ“Œ é‡è¦ç™¼ç¾ç¸½çµ

### âœ… åšå¾—å¥½çš„åœ°æ–¹

1. **é–“è·ç³»çµ±è¡¨ç¾å„ªç§€** ({score['spacing']}/100)
   - å¤§éƒ¨åˆ†é–“è·å€¼ç¬¦åˆ 4px ç¯€å¥
   - Tailwind spacing é¡åä½¿ç”¨è¦ç¯„

2. **è¨­è¨ˆ Token åŸºç¤æ¶æ§‹å®Œæ•´**
   - tailwind.config.js ä¸­å®šç¾©äº†å®Œæ•´çš„é¡è‰²ç³»çµ±
   - CSS Variables æä¾›äº†è‰¯å¥½çš„å‚™æ´æ©Ÿåˆ¶

### âš ï¸ éœ€è¦æ”¹é€²çš„åœ°æ–¹

1. **å­—é«”ç³»çµ±ä¸€è‡´æ€§è¼ƒä½** ({score['typography']}/100)
   - ç™¼ç¾å¤šå€‹æœªå®šç¾©çš„å­—é«”å¤§å°ï¼ˆ14px, 10px ç­‰ï¼‰
   - å»ºè­°å»ºç«‹å®Œæ•´çš„å­—ç´š scale

2. **é¡è‰²ç³»çµ±æœ‰æ”¹é€²ç©ºé–“** ({score['color']}/100)
   - ç™¼ç¾ {len(color_analysis['undefined_colors'])} å€‹æœªå®šç¾©é¡è‰²
   - å»ºè­°å°‡è¿‘ä¼¼é¡è‰²åˆä½µç‚ºå–®ä¸€ token

3. **å…ƒä»¶æ¨£å¼é‡è¤‡åº¦é«˜**
   - Button æœ‰ 30 ç¨®ä¸åŒé¡åçµ„åˆ
   - Card æœ‰ 19 ç¨®ä¸åŒé¡åçµ„åˆ
   - å»ºè­°å»ºç«‹çµ±ä¸€çš„ variant ç³»çµ±

### ğŸ¯ å„ªå…ˆç´šå»ºè­°

**é«˜å„ªå…ˆç´šï¼ˆç«‹å³è™•ç†ï¼‰**:
- çµ±ä¸€æœªå®šç¾©é¡è‰²ï¼ˆä½¿ç”¨é »ç‡ > 5 æ¬¡ï¼‰
- æ¨™æº–åŒ–å­—é«”å¤§å°ï¼ˆç§»é™¤ç¡¬ç·¨ç¢¼çš„ 14px, 10px ç­‰ï¼‰

**ä¸­å„ªå…ˆç´šï¼ˆ2-4 é€±å…§ï¼‰**:
- å»ºç«‹å…ƒä»¶ Variant ç³»çµ±
- æ¸…ç† Deprecated Token

**ä½å„ªå…ˆç´šï¼ˆé•·æœŸè¦åŠƒï¼‰**:
- é·ç§»åˆ° CSS Variables ç‚ºä¸»çš„ Token ç³»çµ±
- å»ºç«‹å…ƒä»¶åº«ï¼ˆNunjucks macrosï¼‰

---

**å ±å‘ŠçµæŸ**
"""
    
    return report

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ” é–‹å§‹æƒæå°ˆæ¡ˆ...")
    results, tokens = scan_project()
    
    print(f"âœ… æƒæå®Œæˆï¼å…±æƒæ {len(results['files_scanned'])} å€‹æª”æ¡ˆ")
    print(f"   - é¡è‰²: {len(results['colors'])} è™•")
    print(f"   - é–“è·: {len(results['spacing'])} è™•")
    print(f"   - å­—é«”: {len(results['typography'])} è™•")
    print(f"   - åœ“è§’: {len(results['borderRadius'])} è™•")
    print(f"   - é™°å½±: {len(results['shadows'])} è™•")
    
    print("\nğŸ“Š ç”Ÿæˆç¨½æ ¸å ±å‘Š...")
    report = generate_report(results, tokens)
    
    # å„²å­˜å ±å‘Š
    report_path = PROJECT_ROOT / "DESIGN_SYSTEM_AUDIT_REPORT.md"
    with open(report_path, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"âœ… å ±å‘Šå·²å„²å­˜è‡³: {report_path}")
    print(f"\nğŸ“ˆ ç¸½é«”ä¸€è‡´æ€§åˆ†æ•¸: {calculate_consistency_score(results, tokens)['overall']}/100")

if __name__ == '__main__':
    main()

