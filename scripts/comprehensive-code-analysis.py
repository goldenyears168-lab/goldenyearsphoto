#!/usr/bin/env python3
"""
å…¨é¢ä»£ç¢¼åˆ†æå·¥å…·
æª¢æ¸¬æœªä½¿ç”¨çš„ä»£ç¢¼ã€ä»£ç¢¼å¥åº·åº¦ã€å°ˆæ¥­åº¦è©•ä¼°
ç”Ÿæˆå…¨æ–¹ä½çš„åˆ†æå ±å‘Š
"""

import ast
import json
import os
import re
from pathlib import Path
from collections import defaultdict
from typing import Dict, List, Tuple

# æ’é™¤çš„ç›®éŒ„
EXCLUDE_DIRS = {
    'node_modules', '_site', '.git', '.cache', '.cursor',
    'images-original', 'assets/images',
}

class CodeAnalyzer:
    def __init__(self, project_root: Path):
        self.project_root = project_root.resolve()
        self.results = {
            'unused_code': {},
            'code_quality': {},
            'best_practices': {},
            'dependencies': {},
            'security': {},
            'performance': {},
            'documentation': {},
            'health_score': 0,
        }
        self.stats = {
            'total_files': 0,
            'total_lines': 0,
            'python_files': 0,
            'js_files': 0,
            'css_files': 0,
            'template_files': 0,
        }
        
    def analyze(self):
        """åŸ·è¡Œå…¨é¢åˆ†æ"""
        print("ğŸ” é–‹å§‹å…¨é¢ä»£ç¢¼åˆ†æ...\n")
        
        # 1. æ”¶é›†æ‰€æœ‰æ–‡ä»¶
        print("ğŸ“ æƒæå°ˆæ¡ˆæ–‡ä»¶...")
        files = self._collect_files()
        self.stats['total_files'] = len(files)
        print(f"   æ‰¾åˆ° {len(files)} å€‹æ–‡ä»¶\n")
        
        # 2. åˆ†ææœªä½¿ç”¨çš„ä»£ç¢¼
        print("ğŸ” åˆ†ææœªä½¿ç”¨çš„ä»£ç¢¼...")
        self._analyze_unused_code(files)
        
        # 3. ä»£ç¢¼è³ªé‡åˆ†æ
        print("ğŸ“Š åˆ†æä»£ç¢¼è³ªé‡...")
        self._analyze_code_quality(files)
        
        # 4. æœ€ä½³å¯¦è¸æª¢æŸ¥
        print("âœ… æª¢æŸ¥æœ€ä½³å¯¦è¸...")
        self._check_best_practices(files)
        
        # 5. ä¾è³´åˆ†æ
        print("ğŸ“¦ åˆ†æä¾è³´é—œä¿‚...")
        self._analyze_dependencies()
        
        # 6. å®‰å…¨æ€§æª¢æŸ¥
        print("ğŸ”’ å®‰å…¨æ€§æª¢æŸ¥...")
        self._check_security(files)
        
        # 7. æ€§èƒ½åˆ†æ
        print("âš¡ æ€§èƒ½åˆ†æ...")
        self._analyze_performance(files)
        
        # 8. æ–‡æª”å®Œæ•´æ€§
        print("ğŸ“ æª¢æŸ¥æ–‡æª”å®Œæ•´æ€§...")
        self._check_documentation(files)
        
        # 9. è¨ˆç®—å¥åº·åº¦è©•åˆ†
        print("ğŸ’¯ è¨ˆç®—å¥åº·åº¦è©•åˆ†...")
        self._calculate_health_score()
        
        return self.results
    
    def _collect_files(self) -> Dict[str, Path]:
        """æ”¶é›†æ‰€æœ‰ä»£ç¢¼æ–‡ä»¶"""
        files = {}
        
        for root, dirs, file_list in os.walk(self.project_root):
            # éæ¿¾æ’é™¤ç›®éŒ„
            dirs[:] = [d for d in dirs if d not in EXCLUDE_DIRS]
            
            for file in file_list:
                file_path = Path(root) / file
                rel_path = file_path.relative_to(self.project_root)
                
                # åªæ”¶é›†ä»£ç¢¼æ–‡ä»¶
                ext = file_path.suffix.lower()
                if ext in {'.py', '.js', '.mjs', '.css', '.njk', '.html'}:
                    files[str(rel_path)] = file_path
                    
                    # çµ±è¨ˆ
                    if ext == '.py':
                        self.stats['python_files'] += 1
                    elif ext in {'.js', '.mjs'}:
                        self.stats['js_files'] += 1
                    elif ext == '.css':
                        self.stats['css_files'] += 1
                    elif ext in {'.njk', '.html'}:
                        self.stats['template_files'] += 1
                    
                    # è¨ˆç®—ç¸½è¡Œæ•¸
                    try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                            self.stats['total_lines'] += len(f.readlines())
                    except:
                        pass
        
        return files
    
    def _analyze_unused_code(self, files: Dict[str, Path]):
        """åˆ†ææœªä½¿ç”¨çš„ä»£ç¢¼"""
        unused = {
            'python_functions': [],
            'python_imports': [],
            'python_variables': [],
            'js_functions': [],
            'js_variables': [],
            'unused_files': [],
        }
        
        # Python æ–‡ä»¶åˆ†æ
        for rel_path, file_path in files.items():
            if file_path.suffix == '.py':
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # è§£æ AST
                    try:
                        tree = ast.parse(content, filename=str(file_path))
                        unused_in_file = self._analyze_python_ast(tree, file_path, files)
                        unused['python_functions'].extend(unused_in_file['functions'])
                        unused['python_imports'].extend(unused_in_file['imports'])
                        unused['python_variables'].extend(unused_in_file['variables'])
                    except SyntaxError:
                        pass
                except Exception as e:
                    pass
        
        # JavaScript æ–‡ä»¶åˆ†æ
        for rel_path, file_path in files.items():
            if file_path.suffix in {'.js', '.mjs'}:
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    unused_in_file = self._analyze_javascript(content, file_path, files)
                    unused['js_functions'].extend(unused_in_file['functions'])
                    unused['js_variables'].extend(unused_in_file['variables'])
                except Exception as e:
                    pass
        
        self.results['unused_code'] = unused
    
    def _analyze_python_ast(self, tree: ast.AST, file_path: Path, all_files: Dict[str, Path]) -> Dict:
        """åˆ†æ Python AST"""
        unused = {
            'functions': [],
            'imports': [],
            'variables': [],
        }
        
        defined_functions = set()
        defined_imports = set()
        defined_variables = set()
        used_names = set()
        
        class Visitor(ast.NodeVisitor):
            def visit_FunctionDef(self, node):
                defined_functions.add(node.name)
                # è·³éç§æœ‰å‡½æ•¸ï¼ˆä»¥ _ é–‹é ­ï¼‰
                if not node.name.startswith('_'):
                    self.generic_visit(node)
            
            def visit_Import(self, node):
                for alias in node.names:
                    defined_imports.add(alias.asname or alias.name.split('.')[0])
            
            def visit_ImportFrom(self, node):
                if node.module:
                    for alias in node.names:
                        defined_imports.add(alias.asname or alias.name)
            
            def visit_Name(self, node):
                if isinstance(node.ctx, ast.Load):
                    used_names.add(node.id)
        
        visitor = Visitor()
        visitor.visit(tree)
        
        # æª¢æŸ¥æœªä½¿ç”¨çš„å‡½æ•¸
        for func_name in defined_functions:
            if func_name not in used_names and not func_name.startswith('_'):
                # æª¢æŸ¥æ˜¯å¦åœ¨å…¶ä»–æ–‡ä»¶ä¸­è¢«ä½¿ç”¨
                if not self._is_used_in_other_files(func_name, file_path, all_files):
                    unused['functions'].append({
                        'file': str(file_path.relative_to(self.project_root)),
                        'name': func_name,
                        'type': 'function'
                    })
        
        # æª¢æŸ¥æœªä½¿ç”¨çš„å°å…¥
        for import_name in defined_imports:
            if import_name not in used_names:
                unused['imports'].append({
                    'file': str(file_path.relative_to(self.project_root)),
                    'name': import_name,
                    'type': 'import'
                })
        
        return unused
    
    def _analyze_javascript(self, content: str, file_path: Path, all_files: Dict[str, Path]) -> Dict:
        """åˆ†æ JavaScript ä»£ç¢¼"""
        unused = {
            'functions': [],
            'variables': [],
        }
        
        # æå–å‡½æ•¸å®šç¾©
        function_pattern = r'(?:function\s+(\w+)|const\s+(\w+)\s*=\s*(?:async\s*)?\(|let\s+(\w+)\s*=\s*(?:async\s*)?\(|var\s+(\w+)\s*=\s*(?:async\s*)?\()'
        defined_functions = set()
        
        for match in re.finditer(function_pattern, content):
            func_name = match.group(1) or match.group(2) or match.group(3) or match.group(4)
            if func_name and not func_name.startswith('_'):
                defined_functions.add(func_name)
        
        # æª¢æŸ¥å‡½æ•¸æ˜¯å¦è¢«èª¿ç”¨
        for func_name in defined_functions:
            # åœ¨ç•¶å‰æ–‡ä»¶ä¸­æŸ¥æ‰¾èª¿ç”¨
            call_pattern = rf'\b{re.escape(func_name)}\s*\('
            if not re.search(call_pattern, content):
                # æª¢æŸ¥æ˜¯å¦åœ¨å…¶ä»–æ–‡ä»¶ä¸­è¢«ä½¿ç”¨
                if not self._is_used_in_other_files(func_name, file_path, all_files, is_js=True):
                    unused['functions'].append({
                        'file': str(file_path.relative_to(self.project_root)),
                        'name': func_name,
                        'type': 'function'
                    })
        
        return unused
    
    def _is_used_in_other_files(self, name: str, current_file: Path, all_files: Dict[str, Path], is_js: bool = False) -> bool:
        """æª¢æŸ¥åç¨±æ˜¯å¦åœ¨å…¶ä»–æ–‡ä»¶ä¸­è¢«ä½¿ç”¨"""
        for rel_path, file_path in all_files.items():
            if file_path == current_file:
                continue
            
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # ç°¡å–®çš„å­—ç¬¦ä¸²åŒ¹é…ï¼ˆå¯ä»¥æ”¹é€²ï¼‰
                if is_js:
                    pattern = rf'\b{re.escape(name)}\s*\('
                else:
                    pattern = rf'\b{re.escape(name)}\b'
                
                if re.search(pattern, content):
                    return True
            except:
                pass
        
        return False
    
    def _analyze_code_quality(self, files: Dict[str, Path]):
        """åˆ†æä»£ç¢¼è³ªé‡"""
        quality = {
            'complexity': {},
            'duplication': [],
            'long_files': [],
            'long_functions': [],
            'code_smells': [],
        }
        
        for rel_path, file_path in files.items():
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    lines = f.readlines()
                    content = ''.join(lines)
                
                # æ–‡ä»¶é•·åº¦æª¢æŸ¥
                if len(lines) > 500:
                    quality['long_files'].append({
                        'file': rel_path,
                        'lines': len(lines),
                        'severity': 'high' if len(lines) > 1000 else 'medium'
                    })
                
                # è¤‡é›œåº¦åˆ†æï¼ˆç°¡å–®ç‰ˆæœ¬ï¼‰
                if file_path.suffix == '.py':
                    complexity = self._calculate_complexity(content, 'python')
                    if complexity > 20:
                        quality['complexity'][rel_path] = complexity
                
                # ä»£ç¢¼ç•°å‘³æª¢æ¸¬
                smells = self._detect_code_smells(content, file_path)
                quality['code_smells'].extend(smells)
                
            except Exception as e:
                pass
        
        self.results['code_quality'] = quality
    
    def _calculate_complexity(self, content: str, lang: str) -> int:
        """è¨ˆç®—ä»£ç¢¼è¤‡é›œåº¦ï¼ˆç°¡åŒ–ç‰ˆï¼‰"""
        complexity = 1  # åŸºç¤è¤‡é›œåº¦
        
        if lang == 'python':
            # è¨ˆç®—æ§åˆ¶æµèªå¥
            complexity += len(re.findall(r'\b(if|elif|else|for|while|try|except|with)\b', content))
            complexity += len(re.findall(r'\b(and|or)\b', content)) * 0.5
        
        return int(complexity)
    
    def _detect_code_smells(self, content: str, file_path: Path) -> List[Dict]:
        """æª¢æ¸¬ä»£ç¢¼ç•°å‘³"""
        smells = []
        
        # è¨»é‡‹æ‰çš„ä»£ç¢¼
        if re.search(r'^\s*//.*\w+.*\(|^\s*#.*\w+.*\(', content, re.MULTILINE):
            smells.append({
                'file': str(file_path.relative_to(self.project_root)),
                'type': 'commented_code',
                'severity': 'low'
            })
        
        # TODO/FIXME è¨»é‡‹
        todo_count = len(re.findall(r'\b(TODO|FIXME|XXX|HACK)\b', content, re.IGNORECASE))
        if todo_count > 0:
            smells.append({
                'file': str(file_path.relative_to(self.project_root)),
                'type': 'todo_comments',
                'count': todo_count,
                'severity': 'medium'
            })
        
        # ç¡¬ç·¨ç¢¼çš„æ•æ„Ÿä¿¡æ¯
        if re.search(r'(password|secret|api_key|token)\s*=\s*["\'][^"\']+["\']', content, re.IGNORECASE):
            smells.append({
                'file': str(file_path.relative_to(self.project_root)),
                'type': 'hardcoded_secrets',
                'severity': 'high'
            })
        
        # console.log èª¿ç”¨ï¼ˆç”Ÿç”¢ç’°å¢ƒï¼‰
        if file_path.suffix in {'.js', '.mjs'}:
            console_logs = len(re.findall(r'console\.(log|debug|info)', content))
            if console_logs > 5:
                smells.append({
                    'file': str(file_path.relative_to(self.project_root)),
                    'type': 'excessive_console_logs',
                    'count': console_logs,
                    'severity': 'low'
                })
        
        return smells
    
    def _check_best_practices(self, files: Dict[str, Path]):
        """æª¢æŸ¥æœ€ä½³å¯¦è¸"""
        practices = {
            'errors': [],
            'warnings': [],
            'suggestions': [],
        }
        
        # æª¢æŸ¥éŒ¯èª¤è™•ç†
        for rel_path, file_path in files.items():
            if file_path.suffix == '.py':
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰é©ç•¶çš„éŒ¯èª¤è™•ç†
                    has_try_except = 'try:' in content or 'except' in content
                    has_error_handling = has_try_except or 'raise' in content
                    
                    # æª¢æŸ¥æ–‡ä»¶æ“ä½œæ˜¯å¦æœ‰éŒ¯èª¤è™•ç†
                    if 'open(' in content and not has_error_handling:
                        practices['warnings'].append({
                            'file': rel_path,
                            'issue': 'æ–‡ä»¶æ“ä½œç¼ºå°‘éŒ¯èª¤è™•ç†',
                            'type': 'error_handling'
                        })
                except:
                    pass
        
        # æª¢æŸ¥ä»£ç¢¼çµ„ç¹”
        # æª¢æŸ¥æ˜¯å¦æœ‰é©ç•¶çš„æ¨¡å¡ŠåŒ–
        py_files = [f for f in files.items() if f[1].suffix == '.py']
        if len(py_files) > 10:
            # æª¢æŸ¥æ˜¯å¦æœ‰é©ç•¶çš„ç›®éŒ„çµæ§‹
            py_dirs = set(str(f[1].parent) for f in py_files)
            if len(py_dirs) == 1:
                practices['suggestions'].append({
                    'issue': 'è€ƒæ…®å°‡ Python æ–‡ä»¶çµ„ç¹”åˆ°å­ç›®éŒ„ä¸­',
                    'type': 'organization'
                })
        
        self.results['best_practices'] = practices
    
    def _analyze_dependencies(self):
        """åˆ†æä¾è³´é—œä¿‚"""
        deps = {
            'unused_packages': [],
            'outdated_packages': [],
            'security_issues': [],
            'duplicate_deps': [],
        }
        
        # è®€å– package.json
        package_json = self.project_root / 'package.json'
        if package_json.exists():
            try:
                with open(package_json, 'r', encoding='utf-8') as f:
                    package_data = json.load(f)
                
                all_deps = {}
                all_deps.update(package_data.get('dependencies', {}))
                all_deps.update(package_data.get('devDependencies', {}))
                
                # æª¢æŸ¥æœªä½¿ç”¨çš„ä¾è³´ï¼ˆç°¡å–®æª¢æŸ¥ï¼‰
                # é€™è£¡å¯ä»¥æ”¹é€²ï¼Œå¯¦éš›æƒæ import/require èªå¥
                
            except Exception as e:
                pass
        
        self.results['dependencies'] = deps
    
    def _check_security(self, files: Dict[str, Path]):
        """å®‰å…¨æ€§æª¢æŸ¥"""
        security = {
            'issues': [],
            'warnings': [],
        }
        
        for rel_path, file_path in files.items():
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # æª¢æŸ¥ SQL æ³¨å…¥é¢¨éšª
                if re.search(r'eval\s*\(|exec\s*\(', content):
                    security['issues'].append({
                        'file': rel_path,
                        'type': 'dangerous_eval',
                        'severity': 'high'
                    })
                
                # æª¢æŸ¥ XSS é¢¨éšªï¼ˆåœ¨æ¨¡æ¿ä¸­ï¼‰
                if file_path.suffix in {'.njk', '.html'}:
                    if re.search(r'<script[^>]*>.*\{\{.*\}\}', content, re.DOTALL):
                        security['warnings'].append({
                            'file': rel_path,
                            'type': 'potential_xss',
                            'severity': 'medium'
                        })
                
            except:
                pass
        
        self.results['security'] = security
    
    def _analyze_performance(self, files: Dict[str, Path]):
        """æ€§èƒ½åˆ†æ"""
        performance = {
            'issues': [],
            'suggestions': [],
        }
        
        # æª¢æŸ¥å¤§æ–‡ä»¶
        for rel_path, file_path in files.items():
            try:
                size = file_path.stat().st_size
                if size > 100 * 1024:  # 100KB
                    performance['suggestions'].append({
                        'file': rel_path,
                        'issue': f'æ–‡ä»¶è¼ƒå¤§ ({size/1024:.1f}KB)ï¼Œè€ƒæ…®æ‹†åˆ†',
                        'type': 'large_file'
                    })
            except:
                pass
        
        self.results['performance'] = performance
    
    def _check_documentation(self, files: Dict[str, Path]):
        """æª¢æŸ¥æ–‡æª”å®Œæ•´æ€§"""
        documentation = {
            'missing_docstrings': [],
            'missing_readme': [],
            'coverage': 0,
        }
        
        # æª¢æŸ¥ README
        readme_files = ['README.md', 'readme.md', 'README.txt']
        has_readme = any((self.project_root / f).exists() for f in readme_files)
        if not has_readme:
            documentation['missing_readme'].append('å°ˆæ¡ˆæ ¹ç›®éŒ„ç¼ºå°‘ README.md')
        
        # æª¢æŸ¥ Python æ–‡ä»¶çš„æ–‡æª”å­—ç¬¦ä¸²
        py_files_with_docs = 0
        py_files_total = 0
        
        for rel_path, file_path in files.items():
            if file_path.suffix == '.py':
                py_files_total += 1
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    
                    # æª¢æŸ¥æ˜¯å¦æœ‰æ¨¡å¡Šç´šæ–‡æª”å­—ç¬¦ä¸²
                    if '"""' in content or "'''" in content:
                        py_files_with_docs += 1
                    else:
                        documentation['missing_docstrings'].append(rel_path)
                except:
                    pass
        
        if py_files_total > 0:
            documentation['coverage'] = (py_files_with_docs / py_files_total) * 100
        
        self.results['documentation'] = documentation
    
    def _calculate_health_score(self):
        """è¨ˆç®—æ•´é«”å¥åº·åº¦è©•åˆ†"""
        score = 100
        deductions = []
        
        # æœªä½¿ç”¨ä»£ç¢¼æ‰£åˆ†
        unused_count = (
            len(self.results['unused_code'].get('python_functions', [])) +
            len(self.results['unused_code'].get('js_functions', [])) +
            len(self.results['unused_code'].get('python_imports', []))
        )
        if unused_count > 0:
            deduction = min(unused_count * 2, 20)
            score -= deduction
            deductions.append(f'æœªä½¿ç”¨ä»£ç¢¼: -{deduction}åˆ†')
        
        # ä»£ç¢¼è³ªé‡å•é¡Œæ‰£åˆ†
        quality_issues = (
            len(self.results['code_quality'].get('long_files', [])) +
            len(self.results['code_quality'].get('code_smells', []))
        )
        if quality_issues > 0:
            deduction = min(quality_issues, 15)
            score -= deduction
            deductions.append(f'ä»£ç¢¼è³ªé‡å•é¡Œ: -{deduction}åˆ†')
        
        # å®‰å…¨æ€§å•é¡Œæ‰£åˆ†
        security_issues = len(self.results['security'].get('issues', []))
        if security_issues > 0:
            deduction = min(security_issues * 10, 30)
            score -= deduction
            deductions.append(f'å®‰å…¨æ€§å•é¡Œ: -{deduction}åˆ†')
        
        # æ–‡æª”å®Œæ•´æ€§
        doc_coverage = self.results['documentation'].get('coverage', 0)
        if doc_coverage < 50:
            deduction = int((50 - doc_coverage) / 10)
            score -= deduction
            deductions.append(f'æ–‡æª”ä¸è¶³: -{deduction}åˆ†')
        
        score = max(0, score)
        
        self.results['health_score'] = score
        self.results['health_deductions'] = deductions
    
    def generate_report(self) -> str:
        """ç”Ÿæˆå ±å‘Š"""
        report = []
        report.append("=" * 80)
        report.append("ğŸ“Š å…¨é¢ä»£ç¢¼åˆ†æå ±å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # å°ˆæ¡ˆçµ±è¨ˆ
        report.append("ğŸ“ˆ å°ˆæ¡ˆçµ±è¨ˆ")
        report.append("-" * 80)
        report.append(f"ç¸½æ–‡ä»¶æ•¸: {self.stats['total_files']}")
        report.append(f"ç¸½ä»£ç¢¼è¡Œæ•¸: {self.stats['total_lines']:,}")
        report.append(f"Python æ–‡ä»¶: {self.stats['python_files']}")
        report.append(f"JavaScript æ–‡ä»¶: {self.stats['js_files']}")
        report.append(f"CSS æ–‡ä»¶: {self.stats['css_files']}")
        report.append(f"æ¨¡æ¿æ–‡ä»¶: {self.stats['template_files']}")
        report.append("")
        
        # å¥åº·åº¦è©•åˆ†
        score = self.results['health_score']
        score_emoji = "ğŸŸ¢" if score >= 80 else "ğŸŸ¡" if score >= 60 else "ğŸ”´"
        report.append(f"{score_emoji} æ•´é«”å¥åº·åº¦è©•åˆ†: {score}/100")
        if self.results.get('health_deductions'):
            report.append("æ‰£åˆ†é …ç›®:")
            for deduction in self.results['health_deductions']:
                report.append(f"  â€¢ {deduction}")
        report.append("")
        
        # æœªä½¿ç”¨çš„ä»£ç¢¼
        report.append("ğŸ” æœªä½¿ç”¨çš„ä»£ç¢¼")
        report.append("-" * 80)
        unused = self.results['unused_code']
        
        if unused.get('python_functions'):
            report.append(f"\nPython æœªä½¿ç”¨å‡½æ•¸ ({len(unused['python_functions'])} å€‹):")
            for item in unused['python_functions'][:10]:  # åªé¡¯ç¤ºå‰10å€‹
                report.append(f"  â€¢ {item['file']}: {item['name']}")
            if len(unused['python_functions']) > 10:
                report.append(f"  ... é‚„æœ‰ {len(unused['python_functions']) - 10} å€‹")
        
        if unused.get('js_functions'):
            report.append(f"\nJavaScript æœªä½¿ç”¨å‡½æ•¸ ({len(unused['js_functions'])} å€‹):")
            for item in unused['js_functions'][:10]:
                report.append(f"  â€¢ {item['file']}: {item['name']}")
            if len(unused['js_functions']) > 10:
                report.append(f"  ... é‚„æœ‰ {len(unused['js_functions']) - 10} å€‹")
        
        if unused.get('python_imports'):
            report.append(f"\nPython æœªä½¿ç”¨å°å…¥ ({len(unused['python_imports'])} å€‹):")
            for item in unused['python_imports'][:10]:
                report.append(f"  â€¢ {item['file']}: {item['name']}")
            if len(unused['python_imports']) > 10:
                report.append(f"  ... é‚„æœ‰ {len(unused['python_imports']) - 10} å€‹")
        
        if not any(unused.values()):
            report.append("âœ… æœªç™¼ç¾æœªä½¿ç”¨çš„ä»£ç¢¼")
        report.append("")
        
        # ä»£ç¢¼è³ªé‡
        report.append("ğŸ“Š ä»£ç¢¼è³ªé‡åˆ†æ")
        report.append("-" * 80)
        quality = self.results['code_quality']
        
        if quality.get('long_files'):
            report.append(f"\néé•·çš„æ–‡ä»¶ ({len(quality['long_files'])} å€‹):")
            for item in quality['long_files']:
                report.append(f"  â€¢ {item['file']}: {item['lines']} è¡Œ ({item['severity']})")
        
        if quality.get('code_smells'):
            report.append(f"\nä»£ç¢¼ç•°å‘³ ({len(quality['code_smells'])} å€‹):")
            for item in quality['code_smells'][:10]:
                report.append(f"  â€¢ {item['file']}: {item['type']} ({item['severity']})")
            if len(quality['code_smells']) > 10:
                report.append(f"  ... é‚„æœ‰ {len(quality['code_smells']) - 10} å€‹")
        
        if not quality.get('long_files') and not quality.get('code_smells'):
            report.append("âœ… ä»£ç¢¼è³ªé‡è‰¯å¥½")
        report.append("")
        
        # æœ€ä½³å¯¦è¸
        report.append("âœ… æœ€ä½³å¯¦è¸æª¢æŸ¥")
        report.append("-" * 80)
        practices = self.results['best_practices']
        
        if practices.get('errors'):
            report.append(f"\nâŒ éŒ¯èª¤ ({len(practices['errors'])} å€‹):")
            for item in practices['errors']:
                report.append(f"  â€¢ {item.get('file', 'N/A')}: {item.get('issue', 'N/A')}")
        
        if practices.get('warnings'):
            report.append(f"\nâš ï¸  è­¦å‘Š ({len(practices['warnings'])} å€‹):")
            for item in practices['warnings'][:5]:
                report.append(f"  â€¢ {item.get('file', 'N/A')}: {item.get('issue', 'N/A')}")
            if len(practices['warnings']) > 5:
                report.append(f"  ... é‚„æœ‰ {len(practices['warnings']) - 5} å€‹")
        
        if practices.get('suggestions'):
            report.append(f"\nğŸ’¡ å»ºè­° ({len(practices['suggestions'])} å€‹):")
            for item in practices['suggestions']:
                report.append(f"  â€¢ {item.get('issue', 'N/A')}")
        
        if not any(practices.values()):
            report.append("âœ… ç¬¦åˆæœ€ä½³å¯¦è¸")
        report.append("")
        
        # å®‰å…¨æ€§
        report.append("ğŸ”’ å®‰å…¨æ€§æª¢æŸ¥")
        report.append("-" * 80)
        security = self.results['security']
        
        if security.get('issues'):
            report.append(f"\nâŒ å®‰å…¨å•é¡Œ ({len(security['issues'])} å€‹):")
            for item in security['issues']:
                report.append(f"  â€¢ {item['file']}: {item['type']} ({item['severity']})")
        
        if security.get('warnings'):
            report.append(f"\nâš ï¸  å®‰å…¨è­¦å‘Š ({len(security['warnings'])} å€‹):")
            for item in security['warnings']:
                report.append(f"  â€¢ {item['file']}: {item['type']} ({item['severity']})")
        
        if not security.get('issues') and not security.get('warnings'):
            report.append("âœ… æœªç™¼ç¾å®‰å…¨å•é¡Œ")
        report.append("")
        
        # æ€§èƒ½
        report.append("âš¡ æ€§èƒ½åˆ†æ")
        report.append("-" * 80)
        performance = self.results['performance']
        
        if performance.get('suggestions'):
            report.append(f"\nğŸ’¡ æ€§èƒ½å»ºè­° ({len(performance['suggestions'])} å€‹):")
            for item in performance['suggestions']:
                report.append(f"  â€¢ {item['file']}: {item['issue']}")
        
        if not performance.get('suggestions'):
            report.append("âœ… æ€§èƒ½è‰¯å¥½")
        report.append("")
        
        # æ–‡æª”
        report.append("ğŸ“ æ–‡æª”å®Œæ•´æ€§")
        report.append("-" * 80)
        doc = self.results['documentation']
        
        if doc.get('missing_readme'):
            report.append(f"\nâš ï¸  ç¼ºå°‘ README æ–‡ä»¶")
        
        if doc.get('missing_docstrings'):
            report.append(f"\nâš ï¸  ç¼ºå°‘æ–‡æª”å­—ç¬¦ä¸²çš„æ–‡ä»¶ ({len(doc['missing_docstrings'])} å€‹):")
            for file in doc['missing_docstrings'][:5]:
                report.append(f"  â€¢ {file}")
            if len(doc['missing_docstrings']) > 5:
                report.append(f"  ... é‚„æœ‰ {len(doc['missing_docstrings']) - 5} å€‹")
        
        report.append(f"\næ–‡æª”è¦†è“‹ç‡: {doc.get('coverage', 0):.1f}%")
        report.append("")
        
        # ç¸½çµå’Œå»ºè­°
        report.append("=" * 80)
        report.append("ğŸ“‹ ç¸½çµèˆ‡å»ºè­°")
        report.append("=" * 80)
        
        recommendations = []
        
        if unused.get('python_functions') or unused.get('js_functions'):
            recommendations.append("â€¢ è€ƒæ…®ç§»é™¤æœªä½¿ç”¨çš„å‡½æ•¸ï¼Œæ¸›å°‘ä»£ç¢¼è¤‡é›œåº¦")
        
        if quality.get('long_files'):
            recommendations.append("â€¢ å°‡éé•·çš„æ–‡ä»¶æ‹†åˆ†ç‚ºæ›´å°çš„æ¨¡å¡Š")
        
        if security.get('issues'):
            recommendations.append("â€¢ å„ªå…ˆä¿®å¾©å®‰å…¨å•é¡Œ")
        
        if doc.get('coverage', 0) < 50:
            recommendations.append("â€¢ å¢åŠ ä»£ç¢¼æ–‡æª”ï¼Œæé«˜å¯ç¶­è­·æ€§")
        
        if not recommendations:
            recommendations.append("âœ… ä»£ç¢¼è³ªé‡è‰¯å¥½ï¼Œç¹¼çºŒä¿æŒï¼")
        
        for rec in recommendations:
            report.append(rec)
        
        report.append("")
        report.append("=" * 80)
        
        return "\n".join(report)

def main():
    """ä¸»å‡½æ•¸"""
    script_dir = Path(__file__).parent
    project_root = script_dir.parent
    
    analyzer = CodeAnalyzer(project_root)
    results = analyzer.analyze()
    
    # ç”Ÿæˆå ±å‘Š
    report = analyzer.generate_report()
    print("\n" + report)
    
    # ä¿å­˜å ±å‘Šåˆ°æ–‡ä»¶
    report_file = project_root / 'CODE_ANALYSIS_REPORT.txt'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nğŸ’¾ å ±å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    # ä¿å­˜ JSON çµæœ
    json_file = project_root / 'code_analysis_results.json'
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False, default=str)
    
    print(f"ğŸ’¾ è©³ç´°çµæœå·²ä¿å­˜åˆ°: {json_file}")
    
    return 0

if __name__ == '__main__':
    exit(main())
